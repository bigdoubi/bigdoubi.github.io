<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Mengke's website</title>
  <meta name="author" content="Mengke Zhang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="data/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:120%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:120%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Mengke Zhang
                  </p>
                  <p>
                    Hi, I'm Mengke. This website is a brief introduction about myself.
                  </p>
                  <p>
                    In 2021, I received my Bachelor of Engineering degree from <a href="http://ckc.zju.edu.cn/">Chu Kochen Honors College</a> at <a href="https://www.zju.edu.cn/">Zhejiang University</a>. I am currently pursuing a Ph.D. in Robotics at the <a href="http://zju-fast.com/">Fast Lab</a>,  <a href="https://www.zju.edu.cn/">Zhejiang University</a>, under the supervision of Professor <a href="http://zju-fast.com/research-group/yanjun-cao/">Yanjun Cao</a> and <a href="http://zju-fast.com/research-group/fei-gao/">Fei Gao</a>.
                  </p>
                  <p>
                    My research interest is motion planning.
                  </p>
                  <p style="text-align:left">
                  <a href="data/profile/contact.txt" style="margin-right: 20px;">Contact</a>
                  <a href="https://scholar.google.com/citations?user=09DdQT4AAAAJ&hl=zh-CN">Google Scholar</a>
                </p>

                </td>
                <td style="padding:2.5%;width:30%;max-width:40%">
                  <a href="data/profile/pic.jpg"><img
                      style="width:70%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="data/profile/pic.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          

          
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Project</h2>
                  <p>
                    Below are some of the research projects I have been involved in.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:120%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>


        <tr> <td style="padding:10px;width:350px;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted autoplay loop playsinline>
              <source src="data/video/Tase.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;vertical-align:middle">
          <a href="">
            <span class="papertitle">Universal Trajectory Optimization Framework for Differential Drive Robot Class</span>
          </a>
          <br>
          <strong>Mengke Zhang</strong>, Nanhe Chen, Hu Wang, Jianxiong Qiu, Zhichao Han, Qiuyu Ren, Chao Xu, Fei Gao, Yanjun Cao
          <br>
          <em>IEEE Transactions on Automation Science and Engineering (T-ASE)</em>, 2025, published 
          <br>
          <a href="https://zju-fast-lab.github.io/DDR-opt/">Website</a>, <a href="data/paper/tase.pdf">Paper</a>, <a href="https://www.bilibili.com/video/BV1gJxveMEm8/">Video</a>


          <p style="text-align:justify;">
            本工作给出了一种差速驱动机器人在复杂环境中轨迹优化方法，提出了一种基于运动状态轨迹表示的通用优化框架。该框架通过直接参数化角速度和线速度（而非传统的位置坐标），从根本上规避了非完整动力学约束带来的奇异性问题，并首次在单一连续轨迹中统一建模了机器人的前向/后向运动与侧滑效应。其轻量化设计（平均计算时间仅10.47ms）实现了实时的高质量轨迹生成，显著优于现有方法（如TEB耗时增加20倍，DF方法存在低速奇异性）。实验在三种真实DDR平台（双轮、四轮滑移转向、履带式）的拥挤和狭窄环境中验证了其高效性、通用性与鲁棒性。
            <br>
            This work gives the trajectory optimization for differential drive robots (DDRs) in complex environments by introducing a universal framework based on Motion State (MS) trajectory representation. By directly parameterizing angular and linear velocities (instead of traditional Cartesian positions), the framework inherently circumvents singularities caused by nonholonomic dynamics and, for the first time, unifies forward/backward motion and lateral slip within a single continuous trajectory. Its lightweight design (average computation time ~10.47ms) enables real-time generation of high-quality trajectories, significantly outperforming state-of-the-art methods (e.g., TEB being ~20x slower, DF suffering from low-velocity singularities). Extensive experiments across three real DDR platforms (two-wheeled, four-wheeled skid-steer, tracked) in crowded and narrow scenarios validate its efficiency, universality, and robustness.
          </p>
        </td>
        </tr>



        <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted autoplay loop playsinline>
              <source src="data/video/ICRA2025.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="">
            <span class="papertitle">Efficient Trajectory Generation Based on Traversable Planes in 3D Complex Architectural Spaces</span>
          </a>
          <br>
          <strong>Mengke Zhang</strong>*, Zhihao Tian* , Yaoguang Xia, Chao Xu, Fei Gao, Yanjun Cao
          <br>
          <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2025, accepted <br>
          <a href="data/paper/icra2025.pdf">Paper</a>, <a href="https://www.bilibili.com/video/BV114QnYiEWf/">Video</a>
    <p style="text-align:justify;">
            本研究聚焦于地面机器人在复杂多层建筑空间（如含楼梯、斜坡）中的高效导航问题，提出了一种基于可通行平面图（plane-graph） 的轨迹生成方法。该方法通过分割、合并、分类和连接点云数据，提取出代表可行区域（地面、斜坡、楼梯）的可通行平面，并构建轻量化的平面图，将3D空间的导航问题高效地转化为平面内与平面间的路径规划。其基于运动状态（MS）的轨迹优化方法，针对性地引入了楼梯场景的严格朝向约束（防止侧翻）和斜坡场景的重力影响速度约束，确保了机器人在高风险结构上的运动安全性与机动性。实验在多种仿真建筑环境及真实九段螺旋楼梯场景中验证了该方法的有效性（轨迹优化时间约51ms）与实用性，相比直接在点云或高程图上规划的方法展现出显著优势。
            <br>
            This work focuses on efficient navigation for ground robots in complex multi-layered architectural spaces (e.g., containing stairs, slopes) by proposing a trajectory generation method based on a traversable plane-graph. The method segments, merges, classifies, and connects point cloud data to extract traversable planes representing navigable regions (ground, slopes, stairs), and constructs a lightweight plane-graph, effectively reducing the 3D navigation problem to path planning within and between planes. Leveraging a Motion State (MS) based trajectory optimization, it specifically incorporates strict orientation constraints for stairs (to prevent tipping) and gravity-influenced velocity constraints for slopes, ensuring safe and agile operation on high-risk structures. Experiments across diverse simulated buildings and a challenging real-world nine-segment spiral staircase validate the method's effectiveness (~51ms trajectory optimization time) and practicality, demonstrating significant advantages over methods that plan directly on point clouds or elevation maps.
          </p>
        </td>
        </tr>


        <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted autoplay loop playsinline>
              <source src="data/video/ICRA2023.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="">
            <span class="papertitle">Trajectory Optimization for 3D Shape-Changing Robots with Differential Mobile Base</span>
          </a>
          <br>
          <strong>Mengke Zhang</strong>, Chao Xu, Fei Gao, Yanjun Cao
          <br>
          <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023, published <br>
          <a href="data/paper/icra2023.pdf">Paper</a>, <a href="https://www.bilibili.com/video/BV1RW4y1v7ba/">Video</a>
    <p style="text-align:justify;">
            本研究针对形状可变的差速驱动机器人（SCR-DB）在密集3D环境中导航的挑战，提出了一种实时时空轨迹优化方法。该方法创新性地将机器人整体（移动底盘和变形关节）建模为统一的多项式轨迹，同时满足底盘的非完整动力学约束和关节的动力学约束。为克服低速时角速度/角加速度约束的强非线性突变问题，设计了基于激活函数的密集采样策略，仅在关键区域增加采样密度以平衡精度与效率（平均计算时间约104.2ms）。通过欧几里得符号距离场（ESDF）约束机器人全形态（非简化点模型）与障碍物的距离确保安全性。仿真与实物实验（含拱桥穿越场景）验证了该方法能生成平滑（关节加加速度降低85%）、安全且动力学可行的轨迹，显著优于传统方法（如TEB的轨迹加加速度高出10倍以上）。
            <br>

            This work addresses the challenge of navigation for shape-changing robots (SCR-DB) with differential-drive bases in dense 3D environments by proposing a real-time spatiotemporal trajectory optimization method. The core innovation lies in modeling the entire robot (mobile base and shape-changing joints) as a unified polynomial trajectory that simultaneously satisfies the base's nonholonomic dynamics and the joints' dynamics. To tackle the strong nonlinearity and abrupt changes in angular velocity/acceleration constraints at low speeds, a novel activation-function-controlled dense sampling strategy is designed, selectively increasing sampling density only in critical regions to balance accuracy and efficiency (average computation time ~104.2ms). Safety is guaranteed by constraining the Euclidean Signed Distance Field (ESDF) distance between the robot's full shape (non-point-mass model) and obstacles. Extensive simulations and real-world experiments (including arch-bridge traversal) validate the method's ability to generate smooth (joint jerk reduced by 85%), safe, and dynamically feasible trajectories, significantly outperforming traditional approaches (e.g., TEB exhibits >10x higher trajectory jerk).
          </p>
        </td>
        </tr>


        <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted autoplay loop playsinline>
              <source src="data/video/unknown.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="">
            <span class="papertitle">Seeing Before Flying: Active perception Trajectory Planning in Unknown 3D Environments with Limited FOV</span>
          </a>
          <br>
          <strong>Mengke Zhang</strong>
          <br>
          <em>working</em>  <br>
          <a href="https://bigdoubi.github.io/Active_Perception_video/">Video</a>
    <p style="text-align:justify;">
本研究突破了无人机在未知复杂环境中导航的感知极限，提出了一种融合主动感知的轨迹规划框架。针对仅配备水平传感器的无人机在未建图3D环境中的导航难题，我们首次实现了安全的大范围竖直方向运动，克服了传统方法在机动过程中因姿态变化导致的感知盲区问题。通过精确建模无人机姿态对FOV的影响，创新性地动态插入并优化"主动感知段"，智能选择最优观测时机与位姿，确保对未知区域的持续有效感知。实验表明，该方法解除了水平FOV对运动的约束，在竖直方向运动场景中较传统策略速度提升超30%，为无人机在室内、丛林等受限空间的密集障碍物环境导航提供了全新解决方案。
            <br>

This work pushes the boundaries of quadrotor navigation in unknown complex environments by proposing an active-perception-embedded trajectory planning framework. For the first time, we enable safe large-scale vertical maneuvers for drones equipped with horizontal sensors only, overcoming perception blindness during agile motions through precise modeling of FOV-attitude coupling. Our key innovation lies in dynamically inserting and optimizing "active perception segments" along the trajectory, which intelligently schedules observation poses/timing to guarantee persistent perception of unknown regions. Simulations demonstrate that the method eliminates traditional horizontal-FOV motion constraints, achieving >30% speed gain in vertical movements while ensuring safety. This breakthrough unlocks new potential for autonomous navigation in cluttered unknown spaces (e.g., indoor factories, dense forests).
          </p>
        </td>
        </tr>

        <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted autoplay loop playsinline>
              <source src="data/video/IROS2025_tan.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="">
            <span class="papertitle">Real-time Spatial-temporal Traversability Assessment via Feature-based Sparse Gaussian Process</span>
          </a>
          <br>
          <strong>Senming Tan*, Zhenyu Hou*, Zhihao Zhang*, Long Xu, Mengke Zhang, Zhaoqi He, Chao Xu, Fei Gao, Yanjun Cao</strong>
          <br>
          <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2025  <br>
          <a href="data/paper/iros2025_tan.pdf">Paper</a>

          <!-- <a href="https://bigdoubi.github.io/Active_Perception_video/">Video</a> -->
    <p style="text-align:justify;">
本研究给出了崎岖地形实时感知方法，通过特征驱动的稀疏高斯过程（FSGP）与时空贝叶斯高斯核（BGK）融合框架，首次实现毫秒级高精度可通行性评估。 利用轻量化特征诱导点（计算耗时仅33.84ms），我们的方法在森林与室内环境中将地形预测误差降低46%，相较传统高程地图（EM）提速3.2倍。传统方法因依赖局部数据且无法融合历史观测（如SGP基线误差达0.2604），在动态环境中面临严重感知退化，而FSGP-BGK通过时空BGK融合保障了实时避障成功率。
<br>
This work pioneers real-time traversability assessment in unstructured terrains via a feature-driven Sparse Gaussian Process (FSGP) integrated with spatio-temporal Bayesian Gaussian Kernel (BGK) fusion, achieving millisecond-level high-precision mapping. Leveraging lightweight inducing points (33.84ms per inference), our approach reduces terrain prediction errors by 46% in forest/indoor scenes and outperforms traditional elevation maps (EM) by 3.2× speed. Whereas conventional methods suffer from perceptual degradation due to isolated local data processing (e.g., SGP baseline error: 0.2604), FSGP-BGK ensures real-time obstacle avoidance through BGK-based historical data fusion enabling autonomous navigation in complex environments where EM fails.


          </p>
        </td>
        </tr>


                <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted autoplay loop playsinline>
              <source src="data/video/IROS2025_wang.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="">
            <span class="papertitle">Real-time Spatial-temporal Traversability Assessment via Feature-based Sparse Gaussian Process</span>
          </a>
          <br>
          <strong>Yijin Wang*, Tingrui Zhang*, Mengke Zhang, Shuhang Ji, Xiaoying Li, Fei Gao</strong>
          <br>
          <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2025  <br>
          <a href="data/paper/iros2025_wang.pdf">Paper</a>, <a href="https://www.bilibili.com/video/BV14eRpYnE8K/">Video</a>
    <p style="text-align:justify;">
本研究给出了任意形状机器人实时轨迹规划方法，通过运动包络体符号距离场（SVSDF）与B样条优化框架，首次实现10Hz高精度重规划。 利用轻量化SVSDF算法（单点计算仅4.03ms），我们的方法在狭窄空间（70%障碍间距<机器人高度）实现连续避障，相比MINCO参数化提速1.89倍。传统方法因几何简化牺牲解空间（如球形近似失败率>60%）且离散采样无法保证连续安全（漏检率>15%），而SVSDF通过精确运动包络建模与B样条局部支撑特性达成100%避障成功率。
<br>
This work pioneers real-time replanning for arbitrarily shaped robots via Swept Volume SDF (SVSDF) and B-spline optimization, achieving 10Hz high-precision trajectory generation. Leveraging lightweight SVSDF computation (4.03ms per point), our method ensures continuous collision avoidance in confined spaces (70% obstacle gaps < robot height) and outperforms MINCO parameterization by 1.89× speed. Whereas conventional approaches sacrifice solution space via geometric simplification (e.g., spherical approximation failure rate >60%) and fail to guarantee safety due to discrete sampling (missed collision >15%), SVSDF enables 100% obstacle avoidance through exact swept-volume modeling and B-spline's local support property solving critical challenges where prior methods collapse.


          </p>
        </td>
        </tr>


                <tr> <td style="padding:10px;width:30%;vertical-align:middle">
          <div class="video-container" style="width: 330px; height: 186.0px;">
            <video width="100%" height="100%" muted autoplay loop playsinline>
              <source src="data/video/IROS2024.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
        </td>
        <td style="padding:20px;width:70%;vertical-align:middle">
          <a href="">
            <span class="papertitle">Novel Design of Reconfigurable Tracked Robot with Geometry-Changing Tracks</span>
          </a>
          <br>
          <strong>Chice Xuan*, Jiadong Lu*, Zhihao Tian, Jiacheng Li, Mengke Zhang, Hanbin Xie, Jianxiong Qiu, Chao Xu, Fei Gao, Yanjun Cao</strong>
          <br>
          <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2024  <br>
          <a href="data/paper/iros2024.pdf">Paper</a>, <a href="https://www.bilibili.com/video/BV1SM4m1y72C/">Video</a>
    <p style="text-align:justify;">
本研究提出一种新型可重构履带机器人设计，通过创新的四滑块椭圆规机构（Qs-ETM） 实现履带几何形态的动态调整，同时保持恒定张力。结合直驱电机提升机械性能与灵活性，解决了现有系统因复杂传动或张力维持困难导致的部署限制。实验验证表明，该设计显著降低摆臂驱动扭矩达68.3%，并减少摆臂剪切应力达67.1%，大幅提升复杂地形通过能力。
<br>
This work introduces a novel reconfigurable tracked robot with geometry-changing tracks, enabled by a Quad-slider Elliptical Trammel Mechanism (Qs-ETM). This mechanism maintains fixed track tension during reconfiguration while integrating direct-drive motors to enhance mechanical properties and agility. The design overcomes limitations of existing systems in transmission complexity and tension sustainability. Real-world experiments demonstrate up to 68.3% reduction in drive torque and 67.1% lower shear stress on flippers, significantly improving terrain traversability.

          </p>
        </td>
        </tr>


        </tbody>
          </table>
          <!-- Thanks -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:center;font-size:small;">
                    Thanks for the website template offered by <a
                      href="https://github.com/jonbarron/jonbarron_website">Jon
                      Barron</a>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>